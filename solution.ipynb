{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "pickled_model = pickle.load(open('final_model_jaccard_2.pkl', 'rb'))\n",
    "# pickled_model.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "def get_scores(X, y, x_predict, return_names=False, return_only_names=False):\n",
    "    if return_only_names is True and return_names is False:\n",
    "        raise ValueError(\"return_only_names cannot be True if return_names is False\")\n",
    "    clf = LogisticRegression(max_iter=3000).fit(X.to_numpy(), y)\n",
    "    scores = clf.predict_proba([x_predict])\n",
    "    if return_names is False:\n",
    "        return scores\n",
    "    else:\n",
    "        classes = clf.classes_\n",
    "        scores = scores.tolist()[0]\n",
    "        classes = [(classes[i], scores[i]) for i in range(10)]\n",
    "        classes.sort(key=lambda x: x[1], reverse=True)\n",
    "        if return_only_names is True:\n",
    "            classes = [i[0] for i in classes]\n",
    "            # print('результаты', classes)\n",
    "        return classes\n",
    "\n",
    "\n",
    "def get_scores_catboost(X, y, x_predict, return_names=False, return_only_names=False):\n",
    "    if return_only_names is True and return_names is False:\n",
    "        raise ValueError(\"return_only_names cannot be True if return_names is False\")\n",
    "    clf = CatBoostClassifier(iterations=1000, learning_rate=0.01, logging_level='Silent').fit(X, y)\n",
    "    scores = clf.predict_proba([x_predict])\n",
    "    if return_names is False:\n",
    "        return scores\n",
    "    else:\n",
    "        classes = clf.classes_\n",
    "        scores = scores.tolist()[0]\n",
    "        classes = [(classes[i], scores[i]) for i in range(10)]\n",
    "        classes.sort(key=lambda x: x[1], reverse=True)\n",
    "        if return_only_names is True:\n",
    "            classes = [i[0] for i in classes]\n",
    "            # print(classes)\n",
    "        return classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pynndescent import NNDescent\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def vid_long(videos: DataFrame, user_id: int, users: DataFrame) -> DataFrame:\n",
    "    tqdm.pandas()\n",
    "    hist = users[users[\"user_id\"] == user_id]\n",
    "    hist = pd.merge(hist, videos, on='item_id').drop(columns=[\"user_id\"], axis=1)\n",
    "    for i in tqdm(range(100)):\n",
    "        hist[f\"v_title_{i}\"] = hist.progress_apply(lambda row: row[f\"v_title_{i}\"] * 2\n",
    "        if ((row[\"watch_time\"] / (row[\"duration\"] / 1000)) > 0.25\n",
    "            if (row[\"duration\"] / 1000) > 300\n",
    "            else row[\"watch_time\"] > 30)\n",
    "        else 1, axis=1)\n",
    "        hist[f\"v_title_{i}\"] = preprocessing.minmax_scale(hist[f\"v_title_{i}\"].T).T\n",
    "    return hist.drop(columns=[\"watch_time\", \"duration\"], axis=1)\n",
    "\n",
    "\n",
    "def like(videos: pd.DataFrame, user_id: int, emotions: pd.DataFrame) -> pd.DataFrame:\n",
    "    emotions = emotions[[\"user_id\", \"item_id\", \"type\"]]\n",
    "    emotions = emotions[emotions[\"user_id\"] == user_id]\n",
    "    emotions = emotions[[\"item_id\", \"type\"]]\n",
    "    # hist = users[users[\"user_id\"] == user_id]\n",
    "    # hist = pd.merge(hist, videos, on='item_id').drop(columns=[\"user_id\"], axis=1)\n",
    "    # hist = pd.merge(hist, emotions, left_on='item_id', right_on=\"C3\")\n",
    "    tqdm.pandas()\n",
    "    new_videos = videos.merge(emotions, on=\"item_id\")\n",
    "    if len(new_videos) != 0:\n",
    "        videos = new_videos\n",
    "        for i in tqdm(range(100)):\n",
    "            videos[f\"vid_title_{i}\"] = videos.progress_apply(\n",
    "                    lambda row: row[f\"vid_title_{i}\"] * 2 if row[\"type\"] == \"pos_emotions\"\n",
    "                    else (0.5 if row[\"type\"] == \"neg_emotions\" else 1), axis=1).to_numpy()\n",
    "            videos[f\"vid_title_{i}\"] = preprocessing.minmax_scale(np.array([videos[f\"vid_title_{i}\"]]).T).T\n",
    "            videos[f\"vid_descr_{i}\"] = preprocessing.minmax_scale(np.array([videos.progress_apply(\n",
    "                    lambda row: row[f\"vid_descr_{i}\"] * 2 if row[\"type\"] == \"pos_emotions\"\n",
    "                    else (0.5 if row[\"type\"] == \"neg_emotions\" else 1), axis=1).to_numpy()]).T).T\n",
    "\n",
    "            # normalize(np.array([videos.progress_apply(\n",
    "            #         lambda row: row[f\"vtitle{i}\"] * 2 if row[\"C4\"] == \"pos_emotions\"\n",
    "            #         else (0.5 if row[\"C4\"] == \"neg_emotions\" else 1), axis=1).to_numpy()]))[0]\n",
    "        return videos.drop(columns=[\"type\"], axis=1)\n",
    "    else:\n",
    "        return videos\n",
    "    # return videos.drop(columns=[\"type\"], axis=1)\n",
    "\n",
    "\n",
    "def make_vector(data: DataFrame, video_ids: list[int], users: DataFrame, emotions: DataFrame, user_id:str):\n",
    "    # print(\"история просмотра\", video_ids)\n",
    "    df = data[data[\"item_id\"].isin(video_ids)]\n",
    "\n",
    "    # vid_long(data, user_id, users)\n",
    "    # likes = like(df, user_id, emotions)\n",
    "\n",
    "    # TODO add weights\n",
    "    return np.average(df.drop(['item_id', 'video_description', 'video_title', 'ctr.CTR_10days_01_08', 'ctr.CTR_10days_21_07', 'ctr.CTR_10days_10_08', 'ctr.CTR_10days_21_08', 'tv_sub', 'season', 'publicated', 'category_title'], axis=1).values, axis=0)\n",
    "    # return np.mean(likes.drop(['item_id', 'video_description', 'video_title', 'ctr.CTR_10days_01_08', 'ctr.CTR_10days_21_07', 'ctr.CTR_10days_10_08', 'ctr.CTR_10days_21_08', 'tv_sub', 'season', 'publicated', 'category_title'], axis=1).values, axis=0)\n",
    "\n",
    "\n",
    "def get_video_corpus(data: DataFrame, index: NNDescent, vector: np.ndarray):\n",
    "    df = data.drop(['item_id', 'video_description', 'video_title', 'ctr.CTR_10days_01_08', 'ctr.CTR_10days_21_07', 'ctr.CTR_10days_10_08', 'ctr.CTR_10days_21_08', 'tv_sub', 'season', 'publicated', 'category_title'], axis=1).columns.to_list()\n",
    "\n",
    "    top100nearest = index.query(pd.DataFrame([vector], columns=df), k=10)\n",
    "    vids_indices = top100nearest[0][0]\n",
    "    res_data = data.iloc[vids_indices]\n",
    "\n",
    "    return res_data.drop(['item_id', 'video_description', 'video_title', 'ctr.CTR_10days_01_08', 'ctr.CTR_10days_21_07', 'ctr.CTR_10days_10_08', 'ctr.CTR_10days_21_08', 'tv_sub', 'season', 'publicated', 'category_title'], axis=1), res_data['item_id'].values\n",
    "\n",
    "\n",
    "def get_10_category(train_hist: pd.DataFrame, new_hist: pd.DataFrame = None) -> list:\n",
    "    if new_hist is not None:\n",
    "        train_hist = train_hist.append(new_hist, ignore_index=True)\n",
    "    cat_columns = [col for col in tqdm(train_hist.columns) if col.startswith('cat')]\n",
    "    cat_data = train_hist[cat_columns]\n",
    "\n",
    "    # подсчет количества 1 в каждом столбце\n",
    "    counts = cat_data.sum()\n",
    "\n",
    "    # сортировка столбцов по убыванию количества 1 и вывод первых 10\n",
    "    top_columns = counts.sort_values(ascending=False)[:10]\n",
    "    return top_columns\n",
    "\n",
    "\n",
    "def get_top_videos_in_cat(cat_name, train_hist: pd.DataFrame, new_hist: pd.DataFrame = None) -> str:\n",
    "    if new_hist is not None:\n",
    "        train_hist = train_hist.append(new_hist, ignore_index=True)\n",
    "    cat_data = train_hist.loc[train_hist[cat_name] == 1]\n",
    "    counts = cat_data['item_id'].value_counts()\n",
    "    return counts.index[0]\n",
    "\n",
    "\n",
    "def get_top_videos(train_hist: pd.DataFrame, new_hist: pd.DataFrame = None) -> list:\n",
    "    top_category = get_10_category(train_hist, new_hist)\n",
    "    return [get_top_videos_in_cat(i, train_hist, new_hist) for i in tqdm(top_category)]\n",
    "\n",
    "\n",
    "def get_popular() -> np.ndarray:\n",
    "    popular = pd.read_csv(\"top_cat.csv\")\n",
    "    popular = data[\"item_id\"].to_numpy()\n",
    "    popular = np.reshape(popular, (10, 10))\n",
    "    result = []\n",
    "    for i in range(10):\n",
    "        result.append(popular[i][random.randint(0, 9)])\n",
    "    result = np.random.permutation(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def create_submission_file(path: str, data: DataFrame, index, users: DataFrame, emotions: DataFrame):\n",
    "    test_file = pd.read_csv(path)\n",
    "    user_ids = test_file[\"user_id\"].values\n",
    "    preds = []\n",
    "    for idx, user_id in enumerate(tqdm(user_ids)):\n",
    "        x_predict = make_vector(data, users[users[\"user_id\"] == user_id][\"item_id\"].values, users, emotions, user_id)\n",
    "        if len(x_predict) == 0:\n",
    "            preds.append(get_popular)\n",
    "            break\n",
    "        corpus, target = get_video_corpus(data, index, x_predict)\n",
    "        preds.append(target)\n",
    "        # preds.append(get_scores(corpus, target, x_predict, return_names=True, return_only_names=True))\n",
    "\n",
    "        if idx % 5 == 0:\n",
    "            submission = pd.DataFrame({\"user_id\": user_ids[0:idx], \"recs\": preds})\n",
    "            submission.to_csv(\"submission\" + idx + \".csv\", index=False)\n",
    "\n",
    "\n",
    "    submission = pd.DataFrame({\"user_id\": user_ids, \"recs\": preds})\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# pickled_model.prepare()\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfinal_df.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     10\u001B[0m users \u001B[38;5;241m=\u001B[39m pq\u001B[38;5;241m.\u001B[39mread_table(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_dataset_RUTUBE/player_starts_train.parquet\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mto_pandas()\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[0;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    330\u001B[0m     )\n\u001B[0;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    936\u001B[0m     dialect,\n\u001B[1;32m    937\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    946\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m    947\u001B[0m )\n\u001B[1;32m    948\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 950\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    608\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[1;32m    610\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[0;32m--> 611\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1778\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   1771\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[1;32m   1772\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1773\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[1;32m   1774\u001B[0m     (\n\u001B[1;32m   1775\u001B[0m         index,\n\u001B[1;32m   1776\u001B[0m         columns,\n\u001B[1;32m   1777\u001B[0m         col_dict,\n\u001B[0;32m-> 1778\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[1;32m   1779\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\n\u001B[1;32m   1780\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1782\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:232\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m    230\u001B[0m     chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reader\u001B[38;5;241m.\u001B[39mread_low_memory(nrows)\n\u001B[1;32m    231\u001B[0m     \u001B[38;5;66;03m# destructive to chunks\u001B[39;00m\n\u001B[0;32m--> 232\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43m_concatenate_chunks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    234\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    235\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reader\u001B[38;5;241m.\u001B[39mread(nrows)\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:402\u001B[0m, in \u001B[0;36m_concatenate_chunks\u001B[0;34m(chunks)\u001B[0m\n\u001B[1;32m    390\u001B[0m             result[name] \u001B[38;5;241m=\u001B[39m array_type\u001B[38;5;241m.\u001B[39m_concat_same_type(\n\u001B[1;32m    391\u001B[0m                 arrs  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m    392\u001B[0m             )\n\u001B[1;32m    393\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    394\u001B[0m             \u001B[38;5;66;03m# error: Argument 1 to \"concatenate\" has incompatible\u001B[39;00m\n\u001B[1;32m    395\u001B[0m             \u001B[38;5;66;03m# type \"List[Union[ExtensionArray, ndarray[Any, Any]]]\"\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    400\u001B[0m             \u001B[38;5;66;03m# , Sequence[Sequence[Sequence[Sequence[\u001B[39;00m\n\u001B[1;32m    401\u001B[0m             \u001B[38;5;66;03m# _SupportsArray[dtype[Any]]]]]]]\"\u001B[39;00m\n\u001B[0;32m--> 402\u001B[0m             result[name] \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m    404\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m warning_columns:\n\u001B[1;32m    405\u001B[0m     warning_names \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(warning_columns)\n",
      "File \u001B[0;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36mconcatenate\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pynndescent import NNDescent\n",
    "\n",
    "# pickled_model = pickle.load(open('final_model_jaccard.pkl', 'rb'))\n",
    "# print(0)\n",
    "# pickled_model.prepare()\n",
    "# data = pd.read_csv(\"final_df.csv\")\n",
    "# print('1')\n",
    "users = pq.read_table('train_dataset_RUTUBE/player_starts_train.parquet').to_pandas()\n",
    "print('2')\n",
    "# train_hist = pd.merge(users, data, on='item_id').drop(columns=[\"user_id\"], axis=1)\n",
    "# try:\n",
    "    # new_users = pd.read_csv(\"new_player_starts_train.csv\")\n",
    "# except FileNotFoundError:\n",
    "#     new_users = None\n",
    "# new_hist = pd.merge(new_users, data, on='item_id').drop(columns=[\"user_id\"], axis=1)\n",
    "print('3')\n",
    "emotions = pd.read_csv(\"train_dataset_RUTUBE/emotions.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vn/wf1rpzp51jj_bp2lz71rs3q80000gn/T/ipykernel_784/257456476.py:1: DtypeWarning: Columns (252) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"final_df_2.csv\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"final_df_2.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "data.drop('Unnamed: 0', inplace=True, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "users = pq.read_table('train_dataset_RUTUBE/player_starts_train.parquet').to_pandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "emotions = pd.read_csv(\"train_dataset_RUTUBE/emotions.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "data['ctr.CTR_10days_21_07'].fillna(data['ctr.CTR_10days_21_07'].mode()[0], inplace=True)\n",
    "data['ctr.CTR_10days_01_08'].fillna(data['ctr.CTR_10days_01_08'].mode()[0], inplace=True)\n",
    "data['ctr.CTR_10days_10_08'].fillna(data['ctr.CTR_10days_10_08'].mode()[0], inplace=True)\n",
    "data['ctr.CTR_10days_21_08'].fillna(data['ctr.CTR_10days_21_08'].mode()[0], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "data.drop(['tv_title'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data[data.isna().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         item_id  vid_title_0  vid_title_1  vid_title_2  vid_title_3  \\\n",
      "0   video_165654     0.317030     0.583350     0.319950     0.233488   \n",
      "1  video_1173704     0.481264     0.387798     0.602036     0.802317   \n",
      "2    video_23927     0.648496     0.440843     0.160715     0.613938   \n",
      "3  video_1003780     0.203357     0.307920     0.590847     0.516022   \n",
      "4   video_105383     0.744297     0.835887     0.621679     0.773973   \n",
      "\n",
      "   vid_title_4  vid_title_5  vid_title_6  vid_title_7  vid_title_8  ...  \\\n",
      "0     0.397311     0.335484     0.683385     0.544738     0.459705  ...   \n",
      "1     0.655285     0.626316     0.562532     0.271270     0.515960  ...   \n",
      "2     0.367600     0.542256     0.304734     0.719216     0.541566  ...   \n",
      "3     0.755484     0.283917     0.717133     0.625334     0.525521  ...   \n",
      "4     0.504829     0.539626     0.493591     0.560223     0.590561  ...   \n",
      "\n",
      "   ctr.CTR_10days_01_08  ctr.CTR_10days_10_08  ctr.CTR_10days_21_08  \\\n",
      "0                   0.0                   0.0                   0.0   \n",
      "1                   0.0                   0.0                   0.0   \n",
      "2                   0.0                   0.0                   0.0   \n",
      "3                   1.0                   0.0                   0.0   \n",
      "4                   0.0                   0.0                   0.0   \n",
      "\n",
      "   upld_year  upld_month  upld_day  upld_hour  upld_minute  upld_second  \\\n",
      "0       2022          12         8         13           53            5   \n",
      "1       2022           3        24          9           19           15   \n",
      "2       2022           3        19         17           41           49   \n",
      "3       2021           2        20         11           50           53   \n",
      "4       2023           8        11          9            2            7   \n",
      "\n",
      "   upld_dayofweek  \n",
      "0               3  \n",
      "1               3  \n",
      "2               5  \n",
      "3               5  \n",
      "4               4  \n",
      "\n",
      "[5 rows x 267 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train, test = train_test_split(data, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# neighbors = pickled_model.query(test.drop(['item_id', 'video_description', 'tv_title', 'video_title', 'CTR_10days_01_08', 'CTR_10days_21_07', 'CTR_10days_10_08', 'CTR_10days_21_08', 'tv_sub', 'season', 'publicated', 'category_title'], axis=1).head(10), k=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pickled_model.query(train.drop(['item_id', 'video_description', 'tv_title', 'video_title', 'CTR_10days_01_08', 'CTR_10days_21_07', 'CTR_10days_10_08', 'CTR_10days_21_08', 'tv_sub', 'season', 'publicated', 'category_title'], axis=1).head(10), k=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for i in neighbors[0][1]:\n",
    "#     print(data[data['item_id'] == train.iloc[i].item_id].video_title)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1025987    Арай Чобанян показал палату в которой рожает И...\n",
      "Name: video_title, dtype: object\n",
      "468859    LAUNCH ● X-DIAG PRO3 и DIAGZONE PRO ● АКТИВАЦИ...\n",
      "Name: video_title, dtype: object\n",
      "1638170    1992  Реклама Барби Маттел Голливудские Волосы...\n",
      "Name: video_title, dtype: object\n",
      "423766    АСМР Карта Нурсултана в Казахстане ??\n",
      "Name: video_title, dtype: object\n",
      "1597720    Micro Machines (NES Dendy 8bit) - Full Walkthr...\n",
      "Name: video_title, dtype: object\n",
      "1698657    Кинетический песок АСМР • Видео для расслаблен...\n",
      "Name: video_title, dtype: object\n",
      "67347    Зефирантес Выскочка_Расцвел Зефирантес_Красота...\n",
      "Name: video_title, dtype: object\n",
      "872393    «Повышенная государственная академическая стип...\n",
      "Name: video_title, dtype: object\n",
      "1564649    Вестница весны - под музыку, для любителей про...\n",
      "Name: video_title, dtype: object\n",
      "79079    А. Брицын \"Рождество\" И. Дунаевский \"Песня о в...\n",
      "Name: video_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# for video_id in test.head(10)['item_id']:\n",
    "#     print(data[data['item_id'] == video_id].video_title)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/97240 [00:39<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mcreate_submission_file\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain_dataset_RUTUBE/sample_submission.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpickled_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43musers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43memotions\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[38], line 127\u001B[0m, in \u001B[0;36mcreate_submission_file\u001B[0;34m(path, data, index, users, emotions)\u001B[0m\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;66;03m# preds.append(get_scores(corpus, target, x_predict, return_names=True, return_only_names=True))\u001B[39;00m\n\u001B[1;32m    126\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m idx \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m5\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 127\u001B[0m         submission \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser_ids\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrecs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreds\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    128\u001B[0m         submission\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msubmission\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m idx \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    131\u001B[0m submission \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: user_ids, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrecs\u001B[39m\u001B[38;5;124m\"\u001B[39m: preds})\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/pandas/core/frame.py:664\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[0;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[1;32m    658\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_mgr(\n\u001B[1;32m    659\u001B[0m         data, axes\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m\"\u001B[39m: index, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m: columns}, dtype\u001B[38;5;241m=\u001B[39mdtype, copy\u001B[38;5;241m=\u001B[39mcopy\n\u001B[1;32m    660\u001B[0m     )\n\u001B[1;32m    662\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m    663\u001B[0m     \u001B[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001B[39;00m\n\u001B[0;32m--> 664\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[43mdict_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmanager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    665\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ma\u001B[38;5;241m.\u001B[39mMaskedArray):\n\u001B[1;32m    666\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mma\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmrecords\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmrecords\u001B[39;00m\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/pandas/core/internals/construction.py:493\u001B[0m, in \u001B[0;36mdict_to_mgr\u001B[0;34m(data, index, columns, dtype, typ, copy)\u001B[0m\n\u001B[1;32m    489\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    490\u001B[0m         \u001B[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001B[39;00m\n\u001B[1;32m    491\u001B[0m         arrays \u001B[38;5;241m=\u001B[39m [x\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m arrays]\n\u001B[0;32m--> 493\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marrays_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtyp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconsolidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/pandas/core/internals/construction.py:118\u001B[0m, in \u001B[0;36marrays_to_mgr\u001B[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verify_integrity:\n\u001B[1;32m    116\u001B[0m     \u001B[38;5;66;03m# figure out the index, if necessary\u001B[39;00m\n\u001B[1;32m    117\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 118\u001B[0m         index \u001B[38;5;241m=\u001B[39m \u001B[43m_extract_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    119\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    120\u001B[0m         index \u001B[38;5;241m=\u001B[39m ensure_index(index)\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/pandas/core/internals/construction.py:666\u001B[0m, in \u001B[0;36m_extract_index\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m    664\u001B[0m lengths \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mset\u001B[39m(raw_lengths))\n\u001B[1;32m    665\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(lengths) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 666\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll arrays must be of the same length\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    668\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m have_dicts:\n\u001B[1;32m    669\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    670\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    671\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "create_submission_file(\"train_dataset_RUTUBE/sample_submission.csv\", data, pickled_model, users, emotions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               item_id  vid_title_0  vid_title_1  vid_title_2  vid_title_3  \\\n",
      "0         video_165654     0.317030     0.583350     0.319950     0.233488   \n",
      "1        video_1173704     0.481264     0.387798     0.602036     0.802317   \n",
      "2          video_23927     0.648496     0.440843     0.160715     0.613938   \n",
      "3        video_1003780     0.203357     0.307920     0.590847     0.516022   \n",
      "4         video_105383     0.744297     0.835887     0.621679     0.773973   \n",
      "...                ...          ...          ...          ...          ...   \n",
      "1808057  video_1018741     0.670306     0.513039     0.521495     0.845573   \n",
      "1808058    video_37551     0.620435     0.581103     0.651037     0.274357   \n",
      "1808059   video_575652     0.333735     0.495146     0.391018     0.275300   \n",
      "1808060   video_763853     0.500728     0.563369     0.658009     0.390734   \n",
      "1808061  video_1973653     0.378764     0.417246     0.445300     0.238808   \n",
      "\n",
      "         vid_title_4  vid_title_5  vid_title_6  vid_title_7  vid_title_8  ...  \\\n",
      "0           0.397311     0.335484     0.683385     0.544738     0.459705  ...   \n",
      "1           0.655285     0.626316     0.562532     0.271270     0.515960  ...   \n",
      "2           0.367600     0.542256     0.304734     0.719216     0.541566  ...   \n",
      "3           0.755484     0.283917     0.717133     0.625334     0.525521  ...   \n",
      "4           0.504829     0.539626     0.493591     0.560223     0.590561  ...   \n",
      "...              ...          ...          ...          ...          ...  ...   \n",
      "1808057     0.600612     0.671091     0.516227     0.493718     0.618900  ...   \n",
      "1808058     0.630259     0.620438     0.650479     0.733275     0.603704  ...   \n",
      "1808059     0.481411     0.527331     0.498878     0.565984     0.470713  ...   \n",
      "1808060     0.374857     0.661372     0.695196     0.570819     0.412515  ...   \n",
      "1808061     0.341451     0.358913     0.503645     0.657594     0.423567  ...   \n",
      "\n",
      "         ctr.CTR_10days_01_08  ctr.CTR_10days_10_08  ctr.CTR_10days_21_08  \\\n",
      "0                         0.0                   0.0                   0.0   \n",
      "1                         0.0                   0.0                   0.0   \n",
      "2                         0.0                   0.0                   0.0   \n",
      "3                         1.0                   0.0                   0.0   \n",
      "4                         0.0                   0.0                   0.0   \n",
      "...                       ...                   ...                   ...   \n",
      "1808057                   0.0                   0.0                   0.0   \n",
      "1808058                   0.0                   0.0                   0.0   \n",
      "1808059                   0.0                   0.0                   0.0   \n",
      "1808060                   0.0                   0.0                   0.0   \n",
      "1808061                   0.0                   0.0                   0.0   \n",
      "\n",
      "         upld_year  upld_month  upld_day  upld_hour  upld_minute  upld_second  \\\n",
      "0             2022          12         8         13           53            5   \n",
      "1             2022           3        24          9           19           15   \n",
      "2             2022           3        19         17           41           49   \n",
      "3             2021           2        20         11           50           53   \n",
      "4             2023           8        11          9            2            7   \n",
      "...            ...         ...       ...        ...          ...          ...   \n",
      "1808057       2022           3         8          7           20           18   \n",
      "1808058       2023           8         6         11           30           14   \n",
      "1808059       2023           7        23         11            9           52   \n",
      "1808060       2023           7        16          9           58           34   \n",
      "1808061       2023           5         9         19            6           21   \n",
      "\n",
      "         upld_dayofweek  \n",
      "0                     3  \n",
      "1                     3  \n",
      "2                     5  \n",
      "3                     5  \n",
      "4                     4  \n",
      "...                 ...  \n",
      "1808057               1  \n",
      "1808058               6  \n",
      "1808059               6  \n",
      "1808060               6  \n",
      "1808061               1  \n",
      "\n",
      "[1808062 rows x 267 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.dropna())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: video_title, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "print(data[data['item_id'] == 'user_25219604'].video_title)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1501290    Налоговые новости от Аркадия Брызгалина (9.02.23)\n",
      "Name: video_title, dtype: object\n",
      "781754    HilalDeep - Darkness (Original Mix)\n",
      "Name: video_title, dtype: object\n",
      "1418745    Глазовское водохранилище Владимирская область июль 2018\n",
      "Name: video_title, dtype: object\n",
      "1476713    Слепить сиреноголового из пластилина / Как победить сиреноголового и откуда он взялся\n",
      "Name: video_title, dtype: object\n",
      "737086    Катасонов, Левченко, Хазин анализируют состояние ЦБ РФ, экономики РФ дают прогнозы развития ситу...\n",
      "Name: video_title, dtype: object\n",
      "29344    История появления мультяшного кота scp/ Картун кэт из пластилина\n",
      "Name: video_title, dtype: object\n",
      "1275446    ТЕСТ - i7 12700k мать GIGABYTE Z690 GAMING X DDR4 DDR4-3600mh GTX 1050ti BATTLEFIELD 4\n",
      "Name: video_title, dtype: object\n",
      "370710    Новый мост Гонконг - Чжухай - Макао: как доехать из Гонконга на автобусе. Отзыв Ездили Знаем\n",
      "Name: video_title, dtype: object\n",
      "597171    VID_20230819_104842_544\n",
      "Name: video_title, dtype: object\n",
      "939760    Стройка погреба из шлакоблока своими руками. Александр Поспелов.\n",
      "Name: video_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "v = ['video_1759835', 'video_1805778', 'video_1850494', 'video_1008588', 'video_1755974', 'video_1406947', 'video_1050337', 'video_1302615', 'video_1575452', 'video_1654596']\n",
    "\n",
    "\n",
    "for i in v:\n",
    "    print(data[data['item_id'] == i].video_title)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "user_videos = ['video_1905049', 'video_222807', 'video_2087988', 'video_1516664',\n",
    " 'video_1516664']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1409603    Гости программы «Детали» — психолог Татьяна Руденко, мама первоклассницы Евгения Феоктистова.\\n\\nЛетние каникулы — лучшая часть учебного года, для детей уж точно. Они отдыхают, не думают о контрольных и экзаменах. Но настрой пора менять. Новый учебный год не за горами. Чтобы он прошел гладко, важно настроить ребенка на рабочую волну. Как это сделать, рассказали в программе \"Детали\".\n",
      "Name: video_description, dtype: object\n",
      "212104    «Четыре свадьбы» отправляются в Турцию! Невесты из Стамбула Анастасия и Ирина покажут, как проходят национальные турецкие свадьбы. Анастасия позовёт на своё мероприятие 700 гостей, а Ирина устроит «ночь хны». Свадьбы Ольги и Олеси пройдут в Аланье. Ольга выберет для своего торжества стиль бохо, а Олеся – романтический стиль. Понравятся ли девушкам мероприятия соперниц, узнаем из программы «Четыре свадьбы».\n",
      "Name: video_description, dtype: object\n",
      "313824    В специальном выпуске программы «Четыре свадьбы» мы вспомним яркие моменты мероприятий 112 невест. Самые красивые платья, шикарные банкеты и невероятные истории любви… А также неуместные свадебные подарки и дурацкие конкурсы! Всё это покажет программа «Четыре свадьбы».\n",
      "Name: video_description, dtype: object\n",
      "992098    Невесты приглашают на свои свадьбы! Ирина из Упорово будет удивлять соперниц регистрацией на пивзаводе. Екатерина позвала участниц на свою свадьбу в сказочном стиле. Оксана из Волгограда решила сделать русскую народную свадьбу. А Кристина из Санкт-Петербурга пообещала яркую свадьбу-шоу. Понравятся ли девушкам мероприятия конкуренток, узнаем из программы «Четыре свадьбы».\n",
      "Name: video_description, dtype: object\n",
      "992098    Невесты приглашают на свои свадьбы! Ирина из Упорово будет удивлять соперниц регистрацией на пивзаводе. Екатерина позвала участниц на свою свадьбу в сказочном стиле. Оксана из Волгограда решила сделать русскую народную свадьбу. А Кристина из Санкт-Петербурга пообещала яркую свадьбу-шоу. Понравятся ли девушкам мероприятия конкуренток, узнаем из программы «Четыре свадьбы».\n",
      "Name: video_description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for v in user_videos:\n",
    "    print(data[data['item_id'] == v].video_description)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "recs = ['video_1135690', 'video_1174633', 'video_1084905', 'video_1123959', 'video_1193351', 'video_1250023', 'video_1277946', 'video_1369958', 'video_142279', 'video_15449']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1058118    Музыкальный центр, Aiwa NSX, музыкальные тесты\\n\\nФильм состоит из нескольких частей. Инструкция, распаковка, прослушивание, тесты и ремонт музыкального центра Aiwa NSX V900, сравнение с версией AV90. Глава по ремонту может быть полезной для людей, интересующихся этими аппаратами и желающими привести их в работоспособное состояние. Когда я начинал этим заниматься, примерно полгода назад, то смотрел видеоролики на эту тему в разных источниках. Некоторые моменты были за кадром, и приходилось додумывать самому. Постараюсь в этих фильмах показать все этапы восстановления центра практически без вырезания.\n",
      "Name: video_description, dtype: object\n",
      "335799    Показываю как играть на гитаре песню Король и Шут - Кукла колдуна. Обозначаю аккорды и табы. Так же сделала кавер с эффектом караоке.\\n\\nVK: http://vk.com/corusmusic\\nInstagram: skripa\\n\\n#КорольиШут #КакИграть #Аккорды #КуклаКолдуна #гитара #разбор\n",
      "Name: video_description, dtype: object\n",
      "1705623    • Премьера: ►11 августа 2022◄\\n• Оригинальное название: \"Chong qi di qiu\"\\n• Жанр: фантастика\\n• Страна: Китай\\n• Режиссер: Линь Чжэньчжао\\n• Актеры: Мики Хэ, Ло Ми, Мишель Йе\\n\\nИз-за климатических изменений земля начинает превращаться в огромную пустыню. Чтобы избежать глобальной катастрофы ведущие ученые разрабатывают препарат, способствующий ускоренному размножению растительных клеток, не подозревая что высвобождают стрессовую систему растений, превращая их в опасных хищников, захватывающих всю планету...\\n\\n► Рейтинг ожиданий: 2.8\\n► Рейтинг: 5.1\n",
      "Name: video_description, dtype: object\n",
      "1290156    танцуй если знаешь этот тренд музыка для флешмобатанцуй если знаешь этот тренд музыка для флешмобатанцуй если знаешь этот тренд музыка для флешмобатанцуй если знаешь этот тренд музыка для флешмобатанцуй если знаешь этот тренд музыка для флешмобатанцуй если знаешь этот тренд музыка для флешмобатанцуй если знаешь этот тренд музыка для флешмобатанцуй если знаешь этот тренд музыка для флешмобатанцуй если знаешь этот тренд музыка для флешмобатанцуй если знаешь этот тренд музыка для флешмобатанцуй если знаешь этот тренд музыка для флешмобатанцуй если знаешь этот тренд музыка для флешмобатанцуй если знаешь этот тренд музыка для флешмобатанцуй если знаешь этот тренд музыка для флешмобатанцуй если знаешь этот тренд музыка для флешмоба\n",
      "Name: video_description, dtype: object\n",
      "1371821    зоопарк, лев, животные, новости, дети и родители, приколы, последние новости, случаи в зоопарке, lion, львы, animal, zoo, реакция, в зоопарке, вольер, милана и семья, king, милана, милана филимонова, опасные животные, даня, путин, crimea, смешные видео, familybox vlog, новости россии сегодня, даня и милана, тайган, воспитание детей, топ 10, природа, милана влог, ффгтв влог, ffgtv, фемелибокс влог, фемелибокс, путешествия с детьми, familybox, блогеры, олег зубков, рен тв, крым, как живут блогеры, жизнь миланы филимоновой, мультфильм, жизнь миланы, сегодня новости, репетиция поимки животных, япония львы, ртви, смотреть онлайн, русское тв, rtvi, смотреть новости, сша, lion (organism classification), texas (us state), лев убил львицу, зоопарки сша, зоопарк ловля животных, смешное видео, репетиция ловли льва в японии, новости 360, новости сегодня, попробуй не засмеяться, 360tvru, политика, япония зоопарк, новости в россии, телеканал 360, ловля плюшевого льва, лучшие приколы, вести, свеж...\n",
      "Name: video_description, dtype: object\n",
      "467923    В этом ролике я покажу часть воздушного парада в честь Дня Независимости Украины с внешних камер установленных на хвостовом оперении Ан-225 МРИЯ. Будет руление, взлет, полет над Киевом, над Крещатиком и Майданом Независимости. Наслаждайтесь полетом нашей грациозной птички. А еще хочу отметить что нас уже 100 000. Спасибо всем вам что смотрите, комментируете и вдохновляете на новые ролики.  \\n\\nУсаживайтесь поудобнее.\\nПриятного просмотра.\\nІ обов'язково далі буде !\\n\\nПодпишитесь на канал что-бы не пропустить новые уникальные ролики о жизни экипажей самых больших транспортных самолетов  - Ан-124 Руслан, Ан-225 МРИЯ и Ан-22 АНТЕЙ.\\n👉 https://www.youtube.com/c/DAntonov\\nНа канале вы можете посмотреть уникальные ролики -\\n● видео из кабин самолетов марки АН\\n● увлекательные взлеты и посадки\\n● красочные перелеты над океаном и в горах\\n● восходы и закаты солнца с высоты птичьего полета.\n",
      "Name: video_description, dtype: object\n",
      "1161670    Сегодня в выпуске #Минтранс:\\n• Суда не было, а прав лишили: как вернуть документы обратно?\\n• Греем руки или кто-то \"нагреет\" нас?\\n•  Страх за рулем: что поможет начинающему водителю?\\n• Ни скола, ни трещины: как провести ремонт и не пожалеть об этом?\\n\\n✔ Подпишитесь на канал: http://www.youtube.com/c/mintransrentv?sub_confirmation=1 \\r\\n\\r\\n▶ Официальный сайт РЕН ТВ: http://ren.tv/\\r\\n▶ Группа ВКонтакте: https://vk.com/rentv_channel\\r\\n▶ Яндекс Дезен: https://zen.yandex.ru/rentvchannel\\r\\n▶ Instagram: https://www.instagram.com/rentvchannel/\\r\\n▶ Twitter: https://twitter.com/RenTV\\r\\n▶ Facebook: https://www.facebook.com/rentvkino/\\r\\n▶ Одноклассники: https://ok.ru/rentvchannel\\r\\n\\r\\n#Минтранс #РЕНТВ\n",
      "Name: video_description, dtype: object\n",
      "815649    Поддержите мое видео лайком плииииз\\nТвич Фасолька - https://www.twitch.tv/fasoollka\\nИнства Фасолька - https://www.instagram.com/fassoollka/\\n-*-*\\nкаечка, модестал,фолентас,михалина,генсуха,гаечка,барби,тендерлибае,акулич,байовл,екатзе,аринян,каролина,кира,кирочка\\nфасолька fasoollka стрим твич\\nстрим, фасолька, твич, фолентас, фасолька и андрей, modestal смотрит, фасолька и вова, модестал фэмили, modestal family, модестал, модестал смотрят, follentass, ксюша, fasoollka, modestal, резнов, модэстал, фасолька твич, модестал смотрит, резнов модестал, фасолька смотрит, ксюха, fasoollka смотрит, фасолька у модестал, 15 самых лучших клипов фасольки за неделю, модестал монтаж, девушка ватариса, фасолька реакция, шоу, twitch, fasoolka, реакция модестал, топ моменты твича, нг, новый год, характер, фасолька о своём характере, характер фасольки, жизнь фасольки, фасолька - фасолька, девственность, девственник, уменьшительно ласкательные слова, не люблю уменьшительно-ласкательные фасолька, чт...\n",
      "Name: video_description, dtype: object\n",
      "1452269    Мир электротранспорта таков, что любое даже самое дорогое устройство желательно или необходимо готовить к эксплуатации. В этом видео речь о моноколесе Inmotion V12\\nМоноколесо по цене дистрибъютора можно приобрести и у нас.\\nСтоимость гидроизоляции от 4000р, заказать: https://clck.ru/YXYkZ \\nКупить Inmotion V12: https://clck.ru/bmCtP\\n\\nНаши контакты:\\n\\nЦентр индивидуальной мобильности Михаила Денисова:\\nАдрес: г. Москва, Юрьевский переулок 16а.\\nМы на Яндекс картах: https://yandex.ru/maps/-/CCU4N0aShD\\nМы на Google:  https://goo.gl/maps/sNArfA3QbRA3HtQP6\\nМы на 2Гис: https://go.2gis.com/7prifk\\nтел.: +7(495)260-96-20\\nСайт: https://cim-pro.ru \\nОфициальный телеграмм канал: https://t.me/cim_official \\nНовости в телеграмм: https://t.me/cim_news\\nСообщество VK: https://vk.com/cim_pro Сообщество VK: https://vk.com/cim_pro\n",
      "Name: video_description, dtype: object\n",
      "829627    Лучшие шутки и номера в исполнении Сборной Снежногорска в Высшей лиге сезона 2019 года. 14 декабря состоится финал Высшей лиги , в котором примут участие следующие команды: «Борцы. Северный десант», Сургут Сборная Татнефти, Альметьевск Сборная Снежногорска, Снежногорск «Так-то», ( СФУ, Красноярск) «Наполеон Динамит», (Тюменская область) На канале  @KVN в ближайшее время появятся подборки лучших номеров всех финалистов Высшей лиги 2019 года.\\n\\nYouTube - http://www.youtube.com/kvn\\nОфициальный сайт КВН - http://kvn.ru/\\nVkontakte - http://vk.com/public28490858\\nПриобрести билет на игры Высшей Лиги КВН - https://domkvn.ru\\n\\nКВН #квн2019 #pro квн #rdy #высшая лига #про квн #1/2 финала квн 2019 #кивин 2019 #лучшее квн #финалисты квн #квн 2019 лучшее за сезон #шпеньков #шпеньков интервью #1tv #снежногорск квн #снежногорск квн лучшее #1/4 финала снежногорск #квн финал 2019 #серг\n",
      "Name: video_description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "for i in recs:\n",
    "    print(data[data['item_id'] == i].video_description)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "'vid_descr_0'"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[101]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}